import os
import subprocess
import requests
import librosa
import numpy as np
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, ReplyKeyboardMarkup, KeyboardButton
from telegram.ext import ApplicationBuilder, MessageHandler, filters, ContextTypes, CommandHandler, CallbackQueryHandler
from transformers import pipeline
from dotenv import load_dotenv
import logging
import re
from nltk.tokenize import sent_tokenize
from datetime import datetime
import utils

# Logging setup
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# -----------------------------
# Constants
# -----------------------------
FILLERS_RU = utils.FILLERS_RU

FILLERS_EN = utils.FILLERS_EN

OPTIMAL_WPM_MIN = 120
OPTIMAL_WPM_MAX = 150
user_languages = {}
user_stats = {}

TRANSLATIONS = utils.TRANSLATIONS

# -----------------------------
# API configuration
# -----------------------------
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
BOT_TOKEN = os.getenv("BOT_TOKEN")

if not OPENROUTER_API_KEY or not BOT_TOKEN:
    raise ValueError("Environment variables OPENROUTER_API_KEY or BOT_TOKEN not set")


def get_main_keyboard(lang='en'):
    """Create main menu keyboard based on user language"""
    t = TRANSLATIONS[lang]
    keyboard = [
        [KeyboardButton(t['btn_send_audio'])],
        [KeyboardButton(t['btn_stats']), KeyboardButton(t['btn_tips'])],
        [KeyboardButton(t['btn_settings']), KeyboardButton(t['btn_help'])]
    ]
    return ReplyKeyboardMarkup(keyboard, resize_keyboard=True)


def query_llm(prompt, speech_lang):
    """Query Gemma 3 27B via OpenRouter API for speech analysis"""
    system_content = (
        "You are an expert in public speaking and oratory skills. You analyze speech and provide specific recommendations."
        if speech_lang == "en"
        else "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ—Ä–∞—Ç–æ—Ä—Å–∫–æ–º—É –º–∞—Å—Ç–µ—Ä—Å—Ç–≤—É –∏ –ø—É–±–ª–∏—á–Ω—ã–º –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏—è–º. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å —Ä–µ—á—å –∏ –¥–∞–µ—à—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏."
    )

    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "tngtech/tng-r1t-chimera:free",
        "messages": [
            {
                "role": "system",
                "content": system_content
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        "temperature": 0.7,
        "max_tokens": 1500
    }

    try:
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=60
        )
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]
    except requests.exceptions.RequestException as e:
        logger.error(f"API request error: {e}")
        if hasattr(e.response, 'text'):
            logger.error(f"API response: {e.response.text}")
        return "Error getting recommendations. Please try again later." if speech_lang == "en" else "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."


def count_fillers(text, lang="ru"):
    """Count filler words by tokens"""
    fillers = set(FILLERS_RU if lang == "ru" else FILLERS_EN)
    words = re.findall(r"\b\w+\b", text.lower())

    filler_details = {}
    for w in words:
        if w in fillers:
            filler_details[w] = filler_details.get(w, 0) + 1

    total_count = sum(filler_details.values())
    return total_count, filler_details


def analyze_prosody(y, sr, lang="ru"):
    """Advanced expressiveness analysis: pitch, variability, energy"""
    # Pitch analysis
    pitches, magnitudes = librosa.piptrack(y=y, sr=sr, fmin=75, fmax=350)
    pitch = []
    for i in range(pitches.shape[1]):
        idx = magnitudes[:, i].argmax()
        val = pitches[idx, i]
        if val > 0:
            pitch.append(val)

    pitch = np.array(pitch)
    if len(pitch) > 10:
        pitch = librosa.effects.harmonic(pitch)

    pitch_var = float(np.std(pitch)) if len(pitch) > 1 else 0
    pitch_mean = float(np.mean(pitch)) if len(pitch) > 1 else 0

    # Energy analysis
    energy = librosa.feature.rms(y=y)[0]
    energy_var = float(np.std(energy))
    energy_mean = float(np.mean(energy))

    # Determine monotony level
    if lang == "en":
        monotony = (
            "very low (lively sound)" if pitch_var > 60 else
            "moderate" if pitch_var > 30 else
            "high (monotonous)"
        )
        dynamics = (
            "pronounced dynamics" if energy_var > 0.03 else
            "medium dynamics" if energy_var > 0.015 else
            "flat (almost no volume changes)"
        )
    else:
        monotony = (
            "–æ—á–µ–Ω—å –Ω–∏–∑–∫–∞—è (–∂–∏–≤–æ–µ –∑–≤—É—á–∞–Ω–∏–µ)" if pitch_var > 60 else
            "—É–º–µ—Ä–µ–Ω–Ω–∞—è" if pitch_var > 30 else
            "–≤—ã—Å–æ–∫–∞—è (–º–æ–Ω–æ—Ç–æ–Ω–Ω–æ)"
        )
        dynamics = (
            "—è—Ä–∫–æ –≤—ã—Ä–∞–∂–µ–Ω–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞" if energy_var > 0.03 else
            "—Å—Ä–µ–¥–Ω—è—è –¥–∏–Ω–∞–º–∏–∫–∞" if energy_var > 0.015 else
            "–ø–ª–æ—Å–∫–∞—è (–ø–æ—á—Ç–∏ –Ω–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π –≥—Ä–æ–º–∫–æ—Å—Ç–∏)"
        )

    return {
        "pitch_mean": round(pitch_mean, 1),
        "pitch_variance": round(pitch_var, 1),
        "monotony": monotony,
        "energy_variance": round(energy_var, 4),
        "energy_mean": round(energy_mean, 4),
        "energy_rating": dynamics,
    }


def analyze_speech(audio_path, text, lang="ru"):
    """Improved speech analysis: tempo, pauses, fillers, prosody"""
    y, sr = librosa.load(audio_path, sr=16000)
    duration = librosa.get_duration(y=y, sr=sr)

    # Speed (WPM)
    words = re.findall(r"\b\w+\b", text)
    wpm = len(words) / (duration / 60) if duration > 0 else 0

    # Tempo rating based on language
    if lang == "en":
        tempo_rating = (
            "optimal" if OPTIMAL_WPM_MIN <= wpm <= OPTIMAL_WPM_MAX
            else "too slow" if wpm < OPTIMAL_WPM_MIN
            else "too fast"
        )
    else:
        tempo_rating = (
            "–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π" if OPTIMAL_WPM_MIN <= wpm <= OPTIMAL_WPM_MAX
            else "—Å–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω—ã–π" if wpm < OPTIMAL_WPM_MIN
            else "—Å–ª–∏—à–∫–æ–º –±—ã—Å—Ç—Ä—ã–π"
        )

    # Pauses detection
    pauses = detect_pauses(y, sr)
    short_pauses = sum(1 for p in pauses if 0.3 <= p <= 1.0)
    long_pauses = sum(1 for p in pauses if p > 1.5)

    # Filler words
    fillers_count, filler_details = count_fillers(text, lang)

    # Prosody analysis
    prosody = analyze_prosody(y, sr, lang)

    return {
        "duration_sec": round(duration, 2),
        "word_count": len(words),
        "words_per_minute": round(wpm, 1),
        "tempo_rating": tempo_rating,
        "short_pauses": short_pauses,
        "long_pauses": long_pauses,
        "fillers_count": fillers_count,
        "filler_details": filler_details,
        "prosody": prosody
    }


def detect_pauses(y, sr):
    """More accurate pause detection based on energy"""
    hop = 512
    frame_duration = hop / sr
    energy = librosa.feature.rms(y=y, frame_length=2048, hop_length=hop)[0]

    threshold = np.percentile(energy, 15)  # Dynamic threshold
    silence_frames = np.where(energy < threshold)[0]

    pauses = []
    if len(silence_frames) == 0:
        return pauses

    start = silence_frames[0]
    prev = silence_frames[0]

    for f in silence_frames[1:]:
        if f - prev > 1:
            duration = (prev - start) * frame_duration
            if duration > 0.25:
                pauses.append(duration)
            start = f
        prev = f

    # Add last pause
    duration = (prev - start) * frame_duration
    if duration > 0.25:
        pauses.append(duration)

    return pauses


def analyze_text_quality(text, lang="ru"):
    """Analyze logic, structure and clarity of text"""
    language = "russian" if lang == "ru" else "english"
    sentences = sent_tokenize(text, language=language)

    avg_sentence_len = sum(len(s.split()) for s in sentences) / len(sentences) if sentences else 0

    too_long = [s for s in sentences if len(s.split()) > 20]
    repetitions = {}

    words = re.findall(r"\b\w+\b", text.lower())
    for w in words:
        if len(w) > 4:
            repetitions[w] = repetitions.get(w, 0) + 1
    repetitions = {w: c for w, c in repetitions.items() if c >= 3}

    return {
        "sentence_count": len(sentences),
        "avg_sentence_length": avg_sentence_len,
        "long_sentences": too_long,
        "repetitions": repetitions
    }


def prepare_llm_prompt(text, analysis, lang="ru"):
    """Prepare prompt for LLM based on speech language"""
    filler_list = "\n".join([f"  - '{word}': {count} {'times' if lang == 'en' else '—Ä–∞–∑'}"
                             for word, count in analysis['filler_details'].items()])

    text_quality = analyze_text_quality(text, lang)

    if lang == "en":
        prompt = f"""
Analyze the speech in English and provide specific recommendations for improvement.

üìù SPEECH TEXT:
{text}

üìä METRICS:
- Duration: {analysis['duration_sec']} sec
- Word count: {analysis['word_count']}
- Speech tempo: {analysis['words_per_minute']} words/min ({analysis['tempo_rating']}, norm: {OPTIMAL_WPM_MIN}-{OPTIMAL_WPM_MAX})
- Short pauses: {analysis['short_pauses']}
- Long pauses (hesitations): {analysis['long_pauses']}
- Filler words: {analysis['fillers_count']} times
{filler_list if filler_list else "  (none detected)"}
- Monotony: {analysis['prosody']['monotony']}
- Volume dynamics: {analysis['prosody']['energy_rating']}

üß† TEXT STRUCTURE ANALYSIS:
- Sentence count: {text_quality['sentence_count']}
- Average sentence length: {text_quality['avg_sentence_length']:.1f} words
- Too long sentences: {len(text_quality['long_sentences'])}
- Frequent word repetitions: {text_quality['repetitions']}

üìã TASK
1) Rate the speech on a scale of 1‚Äì10
Evaluate the following parameters:
 - Correctness (pronunciation + grammar)
 - Logic (structure and coherence)
 - Clarity (clear expression)
 - Speech purity (absence of fillers)
 - Expressiveness (intonation, pause work, emotions)

2) You can only use these HTML tags: <b>, <i>, <u>, <code>, <pre>, <a>, <blockquote>. (other tags are strictly prohibited!):

3) Give 3‚Äì5 recommendations for speech improvement
Recommendations should be:
 - specific,
 - implementable,
 - based on metrics and text.

Focus on:
 - tempo,
 - diction,
 - fillers,
 - structure,
 - expressiveness.

4) Find problematic places in the text

Show specific fragments that sound weak, and suggest 2-3 improved versions of each.

Response format (strictly):
 - 5 ratings (1‚Äì10)
 - 5 recommendations in list form
 - Reformulations of problematic phrases
Write concisely, structured and to the point.
"""
    else:
        prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ—á—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –∏ –¥–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è.

üìù –¢–ï–ö–°–¢ –†–ï–ß–ò:
{text}

üìä –ú–ï–¢–†–ò–ö–ò:
- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {analysis['duration_sec']} —Å–µ–∫
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤: {analysis['word_count']}
- –¢–µ–º–ø —Ä–µ—á–∏: {analysis['words_per_minute']} —Å–ª–æ–≤/–º–∏–Ω ({analysis['tempo_rating']}, –Ω–æ—Ä–º–∞: {OPTIMAL_WPM_MIN}-{OPTIMAL_WPM_MAX})
- –ö–æ—Ä–æ—Ç–∫–∏–µ –ø–∞—É–∑—ã: {analysis['short_pauses']}
- –î–ª–∏–Ω–Ω—ã–µ –ø–∞—É–∑—ã (–∑–∞–º–∏–Ω–∫–∏): {analysis['long_pauses']}
- –°–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã: {analysis['fillers_count']} —Ä–∞–∑
{filler_list if filler_list else "  (–Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ)"}
- –ú–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç—å: {analysis['prosody']['monotony']}
- –î–∏–Ω–∞–º–∏–∫–∞ –≥—Ä–æ–º–∫–æ—Å—Ç–∏: {analysis['prosody']['energy_rating']}

üß† –ê–ù–ê–õ–ò–ó –°–¢–†–£–ö–¢–£–†–´ –¢–ï–ö–°–¢–ê:
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {text_quality['sentence_count']}
- –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {text_quality['avg_sentence_length']:.1f} —Å–ª–æ–≤
- –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {len(text_quality['long_sentences'])}
- –ß–∞—Å—Ç—ã–µ –ø–æ–≤—Ç–æ—Ä—ã —Å–ª–æ–≤: {text_quality['repetitions']}

üìã –ó–ê–î–ê–ß–ê
1) –û—Ü–µ–Ω–∏ —Ä–µ—á—å –ø–æ —à–∫–∞–ª–µ 1‚Äì10
–û—Ü–µ–Ω–∏ —Å–ª–µ–¥—É—é—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:
 - –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å (–ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏–µ + –≥—Ä–∞–º–º–∞—Ç–∏–∫–∞)
 - –õ–æ–≥–∏—á–Ω–æ—Å—Ç—å (—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏ —Å–≤—è–∑–Ω–æ—Å—Ç—å)
 - –ü–æ–Ω—è—Ç–Ω–æ—Å—Ç—å (—è—Å–Ω–æ—Å—Ç—å –∏–∑–ª–æ–∂–µ–Ω–∏—è)
 - –ß–∏—Å—Ç–æ—Ç–∞ —Ä–µ—á–∏ (–æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø–∞—Ä–∞–∑–∏—Ç–æ–≤)
 - –í—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–∏–Ω—Ç–æ–Ω–∞—Ü–∏—è, —Ä–∞–±–æ—Ç–∞ —Å –ø–∞—É–∑–∞–º–∏, —ç–º–æ—Ü–∏–∏)

2) —Ç—ã –º–æ–∂–µ—à—å —Ç–æ–ª—å–∫–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ —ç—Ç–∏ HTML —Ç–µ–≥–∏: <b>, <i>, <u>, <code>, <pre>, <a>, <blockquote>. (–¥—Ä—É–≥–∏–µ —Ç–µ–±–µ —Å—Ç—Ä–æ–≥–æ –∑–∞–ø—Ä–µ—â–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å) :

3) –î–∞–π 3‚Äì5 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é —Ä–µ—á–∏
–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å:
 - –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏,
 - —Ä–µ–∞–ª–∏–∑—É–µ–º—ã–º–∏,
 - –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–º–∏ –Ω–∞ –º–µ—Ç—Ä–∏–∫–∞—Ö –∏ —Ç–µ–∫—Å—Ç–µ.

–°—Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞:
 - —Ç–µ–º–ø–µ,
 - –¥–∏–∫—Ü–∏–∏,
 - –ø–∞—Ä–∞–∑–∏—Ç–∞—Ö,
 - —Å—Ç—Ä—É–∫—Ç—É—Ä–µ,
 - –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.

4) –ù–∞–π–¥–∏ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –º–µ—Å—Ç–∞ –≤ —Ç–µ–∫—Å—Ç–µ

–ü–æ–∫–∞–∂–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –∑–≤—É—á–∞—Ç —Å–ª–∞–±–æ, –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ 2-3 —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞ –∫–∞–∂–¥–æ–≥–æ.

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (—Å—Ç—Ä–æ–≥–æ):
 - 5 –æ—Ü–µ–Ω–æ–∫ (1‚Äì10)
 - 5 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Å–ø–∏—Å–∫–æ–º
 - –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Ñ—Ä–∞–∑
–ü–∏—à–∏ –∫—Ä–∞—Ç–∫–æ, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ –∏ –ø–æ –¥–µ–ª—É.
"""
    return prompt


def format_analysis_response(text, analysis, recommendations, model_name, ui_lang="ru"):
    """Format analysis response based on UI language"""
    t = TRANSLATIONS[ui_lang]

    response = f"{t['analysis_title']}\n"
    response += f"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"

    response += f"{t['basic_metrics']}\n"
    response += f"‚è± {analysis['duration_sec']} sec | "
    response += f"üìù {analysis['word_count']} words\n"
    response += f"‚ö°Ô∏è {analysis['words_per_minute']} wpm ({analysis['tempo_rating']})\n"
    response += f"‚è∏ Pauses: {analysis['short_pauses']} short, {analysis['long_pauses']} long\n"
    response += f"üéØ Fillers: {analysis['fillers_count']}\n"

    response += f"{t['speech_quality']}\n"
    response += f"üéµ {analysis['prosody']['monotony']}\n"
    response += f"üîä {analysis['prosody']['energy_rating']}\n"

    response += f"{t['transcription']}\n"
    response += f"<code>{text[:500]}{'...' if len(text) > 500 else ''}</code>\n"

    response += f"{t['recommendations']}"
    response += f"{recommendations}"

    return response


def detect_language(text):
    """Simple language detection based on character patterns"""
    # Count Cyrillic vs Latin characters
    cyrillic_chars = len(re.findall(r'[–∞-—è–ê-–Ø—ë–Å]', text))
    latin_chars = len(re.findall(r'[a-zA-Z]', text))

    # If more than 60% Cyrillic, it's Russian
    if cyrillic_chars > latin_chars and cyrillic_chars > len(text) * 0.3:
        return "ru"
    return "en"


def update_user_stats(user_id, analysis):
    """Update user statistics after analysis"""
    if user_id not in user_stats:
        user_stats[user_id] = {
            'total_analyses': 0,
            'total_wpm': 0,
            'total_fillers': 0,
            'last_analysis_date': None,
            'analyses_history': []
        }

    stats = user_stats[user_id]
    stats['total_analyses'] += 1
    stats['total_wpm'] += analysis['words_per_minute']
    stats['total_fillers'] += analysis['fillers_count']
    stats['last_analysis_date'] = datetime.now().strftime('%Y-%m-%d %H:%M')

    # Store last 10 analyses
    stats['analyses_history'].append({
        'date': stats['last_analysis_date'],
        'wpm': analysis['words_per_minute'],
        'fillers': analysis['fillers_count'],
        'duration': analysis['duration_sec']
    })
    if len(stats['analyses_history']) > 10:
        stats['analyses_history'].pop(0)


# -----------------------------
# Command Handlers
# -----------------------------

async def start_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle /start command with language selection"""
    keyboard = [
        [
            InlineKeyboardButton("üá∑üá∫ –†—É—Å—Å–∫–∏–π", callback_data='lang_ru'),
            InlineKeyboardButton("üá¨üáß English", callback_data='lang_en')
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)

    user_id = update.effective_user.id
    welcome_lang = user_languages.get(user_id, 'en')

    await update.message.reply_text(
        TRANSLATIONS[welcome_lang]['welcome'],
        reply_markup=reply_markup,
        parse_mode='HTML'
    )


async def help_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle /help command"""
    user_id = update.effective_user.id
    lang = user_languages.get(user_id, 'en')
    t = TRANSLATIONS[lang]

    # Send help text and ensure it's displayed
    await update.message.reply_text(
        t['help_text'],
        parse_mode='HTML',
        reply_markup=get_main_keyboard(lang),
        disable_web_page_preview=True
    )


async def stats_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle /stats command - show user statistics"""
    user_id = update.effective_user.id
    lang = user_languages.get(user_id, 'en')
    t = TRANSLATIONS[lang]

    if user_id not in user_stats or user_stats[user_id]['total_analyses'] == 0:
        await update.message.reply_text(
            t['stats_empty'],
            parse_mode='HTML',
            reply_markup=get_main_keyboard(lang)
        )
        return

    stats = user_stats[user_id]
    avg_wpm = round(stats['total_wpm'] / stats['total_analyses'], 1)
    avg_fillers = round(stats['total_fillers'] / stats['total_analyses'], 1)

    response = t['stats_title']
    response += f"{t['total_analyses'].format(stats['total_analyses'])}\n"
    response += f"{t['avg_wpm'].format(avg_wpm)}\n"
    response += f"{t['avg_fillers'].format(avg_fillers)}\n"
    response += f"{t['last_analysis'].format(stats['last_analysis_date'])}\n\n"

    # Add progress chart
    response += "<b>üìà Recent Progress:</b>\n"
    for i, analysis in enumerate(stats['analyses_history'][-5:], 1):
        response += f"{i}. {analysis['date']}: {analysis['wpm']} wpm, {analysis['fillers']} fillers\n"

    await update.message.reply_text(
        response,
        parse_mode='HTML',
        reply_markup=get_main_keyboard(lang)
    )


async def tips_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle /tips command"""
    user_id = update.effective_user.id
    lang = user_languages.get(user_id, 'en')
    t = TRANSLATIONS[lang]

    # Send tips with proper formatting
    message = t['tips_title'] + t['tips_content']
    await update.message.reply_text(
        message,
        parse_mode='HTML',
        reply_markup=get_main_keyboard(lang),
        disable_web_page_preview=True
    )


async def settings_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle /settings command"""
    user_id = update.effective_user.id
    lang = user_languages.get(user_id, 'en')
    t = TRANSLATIONS[lang]

    keyboard = [
        [InlineKeyboardButton(t['btn_change_lang'], callback_data='change_lang')],
        [InlineKeyboardButton(t['btn_back'], callback_data='back_to_menu')]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)

    await update.message.reply_text(
        t['settings_title'],
        reply_markup=reply_markup,
        parse_mode='HTML'
    )


async def about_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle /about command"""
    user_id = update.effective_user.id
    lang = user_languages.get(user_id, 'en')
    t = TRANSLATIONS[lang]

    await update.message.reply_text(
        t['about_text'],
        parse_mode='HTML',
        reply_markup=get_main_keyboard(lang),
        disable_web_page_preview=True
    )


async def text_menu_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle text button presses from menu"""
    user_id = update.effective_user.id
    lang = user_languages.get(user_id, 'en')
    t = TRANSLATIONS[lang]
    text = update.message.text

    if text == t['btn_help'] or text == '‚ùì Help' or text == '‚ùì –ü–æ–º–æ—â—å':
        await help_handler(update, context)
    elif text == t['btn_stats'] or text == 'üìä My Stats' or text == 'üìä –ú–æ—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞':
        await stats_handler(update, context)
    elif text == t['btn_tips'] or text == 'üí° Tips' or text == 'üí° –°–æ–≤–µ—Ç—ã':
        await tips_handler(update, context)
    elif text == t['btn_settings'] or text == '‚öôÔ∏è Settings' or text == '‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏':
        await settings_handler(update, context)
    elif text == t['btn_send_audio'] or text == 'üéô Send Audio' or text == 'üéô –û—Ç–ø—Ä–∞–≤–∏—Ç—å –∞—É–¥–∏–æ':
        prompt_text = "üé§ <b>Ready to analyze!</b>\n\nPlease send a voice message or audio file." if lang == 'en' else "üé§ <b>–ì–æ—Ç–æ–≤ –∫ –∞–Ω–∞–ª–∏–∑—É!</b>\n\n–û—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª."
        await update.message.reply_text(prompt_text, parse_mode='HTML')


async def language_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle language selection and change"""
    query = update.callback_query
    await query.answer()

    user_id = update.effective_user.id

    if query.data == 'change_lang':
        keyboard = [
            [
                InlineKeyboardButton("üá∑üá∫ –†—É—Å—Å–∫–∏–π", callback_data='lang_ru'),
                InlineKeyboardButton("üá¨üáß English", callback_data='lang_en')
            ]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        await query.edit_message_text(
            "üåç <b>Choose language / –í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫:</b>",
            reply_markup=reply_markup,
            parse_mode='HTML'
        )
    elif query.data.startswith('lang_'):
        selected_lang = query.data.split('_')[1]
        user_languages[user_id] = selected_lang
        t = TRANSLATIONS[selected_lang]

        # Edit message to confirm language selection
        await query.edit_message_text(
            t['language_selected'],
            parse_mode='HTML'
        )

        # Send detailed welcome message with instructions
        welcome_detail = (
            "üéØ <b>–ö–∞–∫ –Ω–∞—á–∞—Ç—å:</b>\n\n"
            "1Ô∏è‚É£ –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É <b>üéô –û—Ç–ø—Ä–∞–≤–∏—Ç—å –∞—É–¥–∏–æ</b> –≤–Ω–∏–∑—É\n"
            "2Ô∏è‚É£ –ò–ª–∏ –ø—Ä–æ—Å—Ç–æ –∑–∞–ø–∏—à–∏—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ\n"
            "3Ô∏è‚É£ –ü–æ–ª—É—á–∏—Ç–µ –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤–∞—à–µ–π —Ä–µ—á–∏\n\n"
            "üí° <b>–°–æ–≤–µ—Ç:</b> –ì–æ–≤–æ—Ä–∏—Ç–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫–∞–∫ –æ–±—ã—á–Ω–æ. "
            "–Ø –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ç–µ–º–ø, –ø–∞—É–∑—ã, —Å–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã –∏ –¥–∞–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏!\n\n"
            "üì± –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—é –≤–Ω–∏–∑—É –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –∏–ª–∏ –∫–æ–º–∞–Ω–¥—ã:\n"
            "/help - –ü–æ–¥—Ä–æ–±–Ω–∞—è —Å–ø—Ä–∞–≤–∫–∞\n"
            "/stats - –í–∞—à–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
            "/tips - –°–æ–≤–µ—Ç—ã –ø–æ –æ—Ä–∞—Ç–æ—Ä—Å—Ç–≤—É"
            if selected_lang == 'ru' else
            "üéØ <b>How to start:</b>\n\n"
            "1Ô∏è‚É£ Press the <b>üéô Send Audio</b> button below\n"
            "2Ô∏è‚É£ Or just record a voice message\n"
            "3Ô∏è‚É£ Get detailed analysis of your speech\n\n"
            "üí° <b>Tip:</b> Speak naturally, as you normally do. "
            "I'll analyze tempo, pauses, filler words and give recommendations!\n\n"
            "üì± Use the menu below for navigation or commands:\n"
            "/help - Detailed help\n"
            "/stats - Your statistics\n"
            "/tips - Speaking tips"
        )

        await context.bot.send_message(
            chat_id=user_id,
            text=welcome_detail,
            reply_markup=get_main_keyboard(selected_lang),
            parse_mode='HTML'
        )

        logger.info(f"User {user_id} selected language: {selected_lang}")
    elif query.data == 'back_to_menu':
        lang = user_languages.get(user_id, 'en')
        t = TRANSLATIONS[lang]
        await query.edit_message_text(t['main_menu'], parse_mode='HTML')


pipe = None


async def audio_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Audio message handler (supports Russian and English)"""
    global pipe
    if pipe is None:
        pipe = pipeline(
            "automatic-speech-recognition",
            model="openai/whisper-medium",
            chunk_length_s=30,
            return_timestamps=True,
        )
    user_id = update.effective_user.id
    ui_lang = user_languages.get(user_id, 'en')
    t = TRANSLATIONS[ui_lang]

    logger.info(f"Received audio from user {user_id}")

    input_path = None
    wav_path = None

    try:
        # Send processing status message
        status_message = await update.message.reply_text(t['processing'], parse_mode='HTML')

        # 1. Download audio
        audio_file = await update.message.audio.get_file() if update.message.audio else await update.message.voice.get_file()
        input_path = f"temp_audio_{user_id}.ogg"
        await audio_file.download_to_drive(input_path)
        logger.info(f"Audio saved: {input_path}")

        # 2. Convert to WAV
        await status_message.edit_text(t['converting'], parse_mode="HTML")
        wav_path = f"temp_audio_{user_id}.wav"
        result = subprocess.run(
            ["ffmpeg", "-y", "-i", input_path, "-ar", "16000", "-ac", "1", wav_path],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.PIPE,
            timeout=60
        )
        if result.returncode != 0:
            raise Exception("Audio conversion error")
        logger.info(f"Audio converted: {wav_path}")

        # 3. Transcription
        await status_message.edit_text(t['recognizing'], parse_mode="HTML")
        result = pipe(wav_path)

        text = result["text"]
        chunks = result.get("chunks", [])
        model_name = "Whisper Medium"

        # Detect speech language
        speech_lang = detect_language(text)
        logger.info(f"Detected speech language: {speech_lang}")

        logger.info(f"Model: {model_name}, Text length: {len(text)}, Segments: {len(chunks)}")

        # 4. Speech analysis
        await status_message.edit_text(t['analyzing'], parse_mode="HTML")
        analysis = analyze_speech(wav_path, text, speech_lang)

        # 5. Get LLM recommendations
        await status_message.edit_text(t['generating'], parse_mode="HTML")
        prompt = prepare_llm_prompt(text, analysis, speech_lang)
        recommendations = utils.sanitize_html(query_llm(prompt, speech_lang))

        # 6. Update user statistics
        update_user_stats(user_id, analysis)

        # 7. Format and send response
        response = format_analysis_response(text, analysis, recommendations, model_name, ui_lang)

        # Delete status message
        await status_message.delete()

        # Send result (split if too long)
        if len(response) > 4096:
            parts = [response[i:i + 4096] for i in range(0, len(response), 4096)]
            for part in parts:
                await update.message.reply_text(part, parse_mode="HTML")
        else:
            await update.message.reply_text(response, parse_mode="HTML")

        # Send completion message with stats
        total_analyses = user_stats[user_id]['total_analyses']
        completion_msg = t['analysis_complete'].format(total_analyses)
        await update.message.reply_text(
            completion_msg,
            parse_mode='HTML',
            reply_markup=get_main_keyboard(ui_lang)
        )

        logger.info(f"Analysis complete for user {user_id}")

    except subprocess.TimeoutExpired:
        await update.message.reply_text(t['timeout_error'], parse_mode='HTML')
        logger.error("Timeout during audio conversion")
    except Exception as e:
        error_msg = t['error'].format(str(e))
        await update.message.reply_text(error_msg, parse_mode='HTML')
        logger.error(f"Processing error: {e}", exc_info=True)
    finally:
        # Clean up temporary files
        for path in [input_path, wav_path]:
            if path and os.path.exists(path):
                try:
                    os.remove(path)
                    logger.info(f"Deleted temporary file: {path}")
                except Exception as e:
                    logger.error(f"Could not delete {path}: {e}")


# -----------------------------
# Bot startup
# -----------------------------
def main():
    """Main function to start the bot"""
    logger.info("Starting bot...")

    app = ApplicationBuilder().token(BOT_TOKEN).build()

    # Add command handlers
    app.add_handler(CommandHandler("start", start_handler))
    app.add_handler(CommandHandler("help", help_handler))
    app.add_handler(CommandHandler("stats", stats_handler))
    app.add_handler(CommandHandler("tips", tips_handler))
    app.add_handler(CommandHandler("settings", settings_handler))
    app.add_handler(CommandHandler("about", about_handler))

    # Add callback handlers
    app.add_handler(CallbackQueryHandler(language_callback))

    # Add message handlers
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, text_menu_handler))
    app.add_handler(MessageHandler(filters.AUDIO | filters.VOICE, audio_handler))

    logger.info("‚úÖ Bot started and ready to work!")
    logger.info("Available commands: /start, /help, /stats, /tips, /settings, /about")
    app.run_polling()


if __name__ == "__main__":
    main()
